{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ46j-PD-eXS"
      },
      "source": [
        "Let's set up SparkNLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz8walkjXq0I",
        "outputId": "4fb3c0e7-1cd8-43ea-e0e7-f1faa3b089ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-07-20 04:00:30--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 3.86.22.73\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|3.86.22.73|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2024-07-20 04:00:30--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "Installing PySpark 3.2.3 and Spark NLP 5.4.1\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-20 04:00:30 (30.8 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 5.4.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m579.2/579.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8trkawwfX8bx"
      },
      "outputs": [],
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "import regex as re\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSv2iBclzWMr",
        "outputId": "bc02a1e7-ede8-4837-a41f-8669f8a64150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "explain_document_ml download started this may take some time.\n",
            "Approx size to download 9 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "pipeline = PretrainedPipeline(\"explain_document_ml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTlLDNHZ48Zz"
      },
      "source": [
        "**Introduction**\n",
        "\n",
        "The English language allows for pronouns to serve as both the subject and object of a sentence. This of course, depends on the context and the pronoun must be properly conjugated to make gramatical sense. Focusing on the gendered pronouns (he/him/his and she/her/hers), one may assume that these correspond with each other, able to replace one another in the sentence. However, this is untrue; there are two uses for 'her' and 'his'. 'Her' can be used as both the subject and the object in a sentence. Let's use the example of the sentences 'I saw her' and 'That is her name'. In this example, the 'her' in 'I saw her' is used as the subject of the sentence, or as a personal pronoun. This corresponds with the 'him' in 'I saw him'. The 'her' in 'that is her name' is used as an adjective, describing the 'name'. In this case, it is a possessive determiner pronoun, always used with a noun. It corresponds with 'that is his name'. 'His' can also be used in multiple ways. We have already seen it as the possesive determiner pronoun, but it can also be used as a possessive pronoun in place of a noun, such as in 'that is his'. This version of 'his' is used to describe ownership and corresponds with the feminine 'hers' as in 'that is hers'. Both versions of 'his' serve as the object of the sentence.\n",
        "\n",
        "To take a look at ingrained biases in writing, we can look at the frequency to which these pronouns show up in their different forms. For this, I have decided to explore how these pronouns show up in online FanFiction. FanFiction are unpublished stories, traditionally based on another original story. This can be expanding a story with an author's own interpretations, a story with original characters inserted into the world of an existing piece of literature, an alternate universe from an existing universe, or something else entirely. The phrase 'FanFiction' has moved beyond just stories based on existing universes, and now colloquially can refer to any unpublished story.\n",
        "\n",
        "Due to the open nature of the internet, anyone with a connection can upload and share their stories. Many popular FanFiction websites exist including Wattpad and FanFiction.net, as well as communities on social media platforms such as Tumblr and Reddit. Though not representative of the entire amateur writing community, these sites offer a large selection of stories in many genres and from many existing universes.\n",
        "\n",
        "To achieve this, I will scrape FanFiction stories and analyze their text, looking at the uses and context of gendered pronouns throughout. I will study different genres and existing universes to see if there are significant differences in the appearance of subject versus object gendered pronouns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3dPBdwD660C",
        "outputId": "d336ac9f-d74c-41be-8007-9c597a16729e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  392k  100  392k    0     0  1144k      0 --:--:-- --:--:-- --:--:-- 1145k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  206k  100  206k    0     0   719k      0 --:--:-- --:--:-- --:--:--  718k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  435k  100  435k    0     0  1395k      0 --:--:-- --:--:-- --:--:-- 1400k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  151k  100  151k    0     0   487k      0 --:--:-- --:--:-- --:--:--  488k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 92006  100 92006    0     0   348k      0 --:--:-- --:--:-- --:--:--  349k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  329k  100  329k    0     0  1064k      0 --:--:-- --:--:-- --:--:-- 1065k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  215k  100  215k    0     0   703k      0 --:--:-- --:--:-- --:--:--  702k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  273k  100  273k    0     0   960k      0 --:--:-- --:--:-- --:--:--  963k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  328k  100  328k    0     0  1111k      0 --:--:-- --:--:-- --:--:-- 1114k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  144k  100  144k    0     0   516k      0 --:--:-- --:--:-- --:--:--  515k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  180k  100  180k    0     0   705k      0 --:--:-- --:--:-- --:--:--  707k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  417k  100  417k    0     0  1373k      0 --:--:-- --:--:-- --:--:-- 1378k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  511k  100  511k    0     0  1391k      0 --:--:-- --:--:-- --:--:-- 1389k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  291k  100  291k    0     0   982k      0 --:--:-- --:--:-- --:--:--  983k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  233k  100  233k    0     0   569k      0 --:--:-- --:--:-- --:--:--  568k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  129k  100  129k    0     0   508k      0 --:--:-- --:--:-- --:--:--  509k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  222k  100  222k    0     0   822k      0 --:--:-- --:--:-- --:--:--  824k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  397k  100  397k    0     0  1378k      0 --:--:-- --:--:-- --:--:-- 1376k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  137k  100  137k    0     0   338k      0 --:--:-- --:--:-- --:--:--  339k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  190k  100  190k    0     0   565k      0 --:--:-- --:--:-- --:--:--  564k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  274k  100  274k    0     0   840k      0 --:--:-- --:--:-- --:--:--  841k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  431k  100  431k    0     0  1248k      0 --:--:-- --:--:-- --:--:-- 1251k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  530k  100  530k    0     0  1211k      0 --:--:-- --:--:-- --:--:-- 1209k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  515k  100  515k    0     0  1413k      0 --:--:-- --:--:-- --:--:-- 1416k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  306k  100  306k    0     0  1091k      0 --:--:-- --:--:-- --:--:-- 1091k\n"
          ]
        }
      ],
      "source": [
        "#Fanfiction dataset\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/horror_1.txt\" -o horror_1.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/horror_2.txt\" -o horror_2.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/horror_3.txt\" -o horror_3.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/horror_4.txt\" -o horror_4.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/horror_5.txt\" -o horror_5.txt\n",
        "\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/harrypotter_1.txt\" -o harrypotter_1.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/harrypotter_2.txt\" -o harrypotter_2.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/harrypotter_3.txt\" -o harrypotter_3.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/harrypotter_4.txt\" -o harrypotter_4.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/harrypotter_5.txt\" -o harrypotter_5.txt\n",
        "\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/romance_1.txt\" -o romance_1.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/romance_2.txt\" -o romance_2.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/romance_3.txt\" -o romance_3.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/romance_4.txt\" -o romance_4.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/romance_5.txt\" -o romance_5.txt\n",
        "\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/twilight_1.txt\" -o twilight_1.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/twilight_2.txt\" -o twilight_2.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/twilight_3.txt\" -o twilight_3.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/twilight_4.txt\" -o twilight_4.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/twilight_5.txt\" -o twilight_5.txt\n",
        "\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/warewolf_1.txt\" -o warewolf_1.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/warewolf_2.txt\" -o warewolf_2.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/warewolf_3.txt\" -o warewolf_3.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/warewolf_4.txt\" -o warewolf_4.txt\n",
        "!curl \"https://raw.githubusercontent.com/Jwarmflash/PronounTextAnalysis/main/warewolf_5.txt\" -o warewolf_5.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4QwOZEIkDwJz"
      },
      "outputs": [],
      "source": [
        "horror = ''\n",
        "for i in range(5):\n",
        "  j=i+1\n",
        "  text = str('horror_' + str(j) + '.txt')\n",
        "  horror = horror + (open(text).read())\n",
        "\n",
        "romance = ''\n",
        "for i in range(5):\n",
        "  j=i+1\n",
        "  text = str('romance_' + str(j) + '.txt')\n",
        "  romance = romance + (open(text).read())\n",
        "\n",
        "warewolf = ''\n",
        "for i in range(5):\n",
        "  j=i+1\n",
        "  text = str('warewolf_' + str(j) + '.txt')\n",
        "  warewolf = warewolf + (open(text).read())\n",
        "\n",
        "harrypotter = ''\n",
        "for i in range(5):\n",
        "  j=i+1\n",
        "  text = str('harrypotter_' + str(j) + '.txt')\n",
        "  harrypotter = harrypotter + (open(text).read())\n",
        "\n",
        "twilight = ''\n",
        "for i in range(5):\n",
        "  j=i+1\n",
        "  text = str('twilight_' + str(j) + '.txt')\n",
        "  twilight = twilight + (open(text).read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CpGBnK__SS8A",
        "outputId": "605dcbd8-fdbf-4cc5-a741-2e686bfe7691"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\xa0'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "horror_sentences[11][97]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVsO9AqJ-23u",
        "outputId": "fa4a90b4-378e-43ba-dddc-4501ebb0bc41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Then you will feel a presence behind you...',\n",
              " 'You will feel a tap on your shoulder...',\n",
              " 'The last thing you will see before you die will be the face of the Blind Maiden, staring mercilessly at you with her horrible eyes.',\n",
              " \"It is also said, that the blind maiden will rip out your eyes and take a snapshot of your face so that you will forever be a part of the website's picture gallery.\",\n",
              " 'Baby Blue is an urban legend about a strange game that kids play in bathrooms.',\n",
              " 'If you perform the ritual, they say an evil ghostly infant will appear in your arms.',\n",
              " \"This urban legend is related to the myth of 'Bloody Mary'.\",\n",
              " 'To play \"Blue Baby Blue\", you have to go into the bathroom on your own, turn off the lights and lock the door.',\n",
              " 'Then you stare into the mirror, hold out your arms like you are rocking a baby and repeat the words, \"Baby Blue, Blue Baby\" 13 times without making a mistake.',\n",
              " 'If you do it right, you will suddenly feel the weight of an invisible baby in your arms.']"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_text = horror.replace(u'\\xa0', u' ')\n",
        "cleaned_text = re.sub(r'\\n+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\t+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r' +', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\+', ' ', cleaned_text)\n",
        "\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+\\.?[0-9]*K?', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+\\.?[0-9]*K?', '.', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+', '.', cleaned_text)\n",
        "\n",
        "horror_text_str = cleaned_text\n",
        "horror_sentences = re.split(r'(?<!\\b(?:Mr|Mrs|Ms|Dr)\\.)(?<!\\w\\.\\w.)(?<=[.!?][”\"]?) +', cleaned_text)\n",
        "horror_sentences[50:60]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8WNHmXCORir",
        "outputId": "f445e066-6f6b-4918-b67b-dbedf49d71f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"Why would you want to date Tyson?',\n",
              " 'I have a way bigger dick.',\n",
              " 'My dick is so long it goes from a all the way to z.\"']"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_text = romance.replace(u'\\xa0', u' ')\n",
        "cleaned_text = re.sub(r'\\n+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\t+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r' +', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\*~•°]+', '', cleaned_text)\n",
        "\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+\\.?[0-9]*K?', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+\\.?[0-9]*K?', '.', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+', '.', cleaned_text)\n",
        "\n",
        "romance_text_str = cleaned_text\n",
        "romance_sentences = re.split(r'(?<!\\b(?:Mr|Mrs|Ms|Dr)\\.)(?<!\\w\\.\\w.)(?<=[.!?][”\"]?) +', cleaned_text)\n",
        "romance_sentences[608:611]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1SIV-PrSu56",
        "outputId": "e99370fd-20a9-4142-8110-ad12f11b2c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The pack it led by the Alpha and their mate who is called the Luna (usually female), second in command is the Beta.', 'The Gamma comes in third and is mostly in charge of the warriors.']\n",
            "Can I please bury my face in your neck to smell more of your delicious earthy scent that I pick up with my supernatural nose?\n"
          ]
        }
      ],
      "source": [
        "cleaned_text = warewolf.replace(u'\\xa0', u' ')\n",
        "cleaned_text = re.sub(r'\\n+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\t+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r' +', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\. \\. \\.', '...', cleaned_text)\n",
        "cleaned_text = re.sub(r'[•~\\*]+', '', cleaned_text)\n",
        "\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+\\.?[0-9]*K?', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+\\.?[0-9]*K?', '.', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+', '.', cleaned_text)\n",
        "\n",
        "warewolf_text_str = cleaned_text\n",
        "warewolf_sentences = re.split(r'(?<!\\b(?:Mr|Mrs|Ms|Dr)\\.)(?<!\\w\\.\\w.)(?<=[.!?][”\"]?) +', cleaned_text)\n",
        "print(warewolf_sentences[8:10])\n",
        "print(warewolf_sentences[10793])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXrOLzsIDL4o",
        "outputId": "9a015bcf-bed4-4668-a716-c9482b8c32cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"Shut up Lily,\" he glanced at the picture of mom and dad behind me.',\n",
              " '\"Look it\\'s all Dad\\'s fault.\"',\n",
              " \"I glanced at Dad's equally messy hair in the picture that sat behind me.\",\n",
              " \"Harry was the spitting image of Dad, but with Mum's emerald green, almond shaped eyes.\",\n",
              " 'I was the opposite.',\n",
              " \"I was the spitting image of Mum, but with Dad's round, hazel eyes.\",\n",
              " 'It was nearly impossible to tell we were twins.',\n",
              " 'We sat around for a little while longer, mostly playing games on my iPod, of taking pictures of one another and laughing at how bad we looked.',\n",
              " 'A few minutes before we figured the Dursleys, or rather Dudley, would be finish, I took a glance toward Harry.',\n",
              " 'The knee of his jeans were finally beginning to wear, and his skin was visible through a quickly growing rip.',\n",
              " '\"No funny business,\" snarled Uncle Vernon as we stepped out of the car.',\n",
              " '\"Yes Uncle Vernon\" Harry droned monotonously while at the same time I scoffed what I thought was quietly.',\n",
              " 'Vernon glared at me and shoved a sausagey finger in my face.',\n",
              " '\"You will behave,\" he turned away and I rolled my eyes.',\n",
              " 'Pig saw the gesture and glared at me.',\n",
              " 'I shot a glare right back and Dudley, looking slightly frightened, turned away.',\n",
              " \"He'd brought along one of his friends, Piers Polkiss, Dudley's right hand man.\",\n",
              " \"Dudley was the 'leader' of his little gang, and their favourite thing to do was beat other kids up; kids who were usually younger or smaller than himself.\",\n",
              " \"Their favourite target used to be Harry and me, until they'd encountered me when I was still frustrated at Vernon for confiscating my school supplies so I'd get in trouble at school, and all left with bruises and black eyes.\",\n",
              " 'From then on they became frightened of me, and left me to my business.']"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_text = harrypotter.replace(u'\\xa0', u' ')\n",
        "cleaned_text = re.sub(r'\\n+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\t+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r' +', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\. \\. \\.', '...', cleaned_text)\n",
        "cleaned_text = re.sub(r'[•~\\*°ϟ]+', '', cleaned_text)\n",
        "\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+\\.?[0-9]*K?', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+\\.?[0-9]*K?', '.', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+', '.', cleaned_text)\n",
        "\n",
        "harrypotter_text_str = cleaned_text\n",
        "harrypotter_sentences = re.split(r'(?<!\\b(?:Mr|Mrs|Ms|Dr)\\.)(?<!\\w\\.\\w.)(?<=[.!?][”\"]?) +', cleaned_text)\n",
        "harrypotter_sentences[5000:5020]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJl-XpykJMM7",
        "outputId": "46cc0bad-462e-45da-82ba-479c2eb2e9e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Paul chuckled, sniffing the air in hopes of catching Driana's scent.\",\n",
              " 'However, his happiness fell because there was something odd.',\n",
              " '\"You smell different,\" Paul told her.',\n",
              " '\"I never changed my products,\" Driana told him, confused.',\n",
              " 'The girl furrowed her brows as she stared into his hard eyes.',\n",
              " 'Paul inhaled deeply.',\n",
              " \"He glared and pointed at Driana's jacket.\",\n",
              " '\"Where\\'d you get that?\"',\n",
              " 'The girl hugged the jacket closer to her.',\n",
              " '\"A friend.\"',\n",
              " '\"I don\\'t think you should be friends with them,\" Paul harshly said.',\n",
              " '\"Since when do you control who I hang out with?\"',\n",
              " 'Driana raised a brow at him.',\n",
              " '\"If you know what\\'s good for you, return that to the owner,\" Paul ordered.',\n",
              " '\"I\\'m not one of your wolves to command, Paul,\" Driana argued.',\n",
              " '\"Besides, how would you know what\\'s good for me?\"',\n",
              " '\"Can\\'t you listen, at least?\"',\n",
              " 'Paul growled.',\n",
              " '\"Do you even know who that jacket belongs to?\"',\n",
              " '\"He\\'s one of Dr. Carlisle Cullen\\'s kids,\" Driana glared.']"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_text = twilight.replace(u'\\xa0', u' ')\n",
        "cleaned_text = re.sub(r'\\n+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\t+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r' +', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\+', ' ', cleaned_text)\n",
        "cleaned_text = re.sub(r'\\. \\. \\.', '...', cleaned_text)\n",
        "cleaned_text = re.sub(r'[•~·☾♡☽·︵‿⍣]+', '', cleaned_text)\n",
        "\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+', '.', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][”\"][ ]*[0-9]+\\.?[0-9]*K?', '.\"', cleaned_text)\n",
        "cleaned_text = re.sub(r'[\\.!?][ ]*[0-9]+\\.?[0-9]*K?', '.', cleaned_text)\n",
        "\n",
        "twilight_text_str = cleaned_text\n",
        "twilight_sentences = re.split(r'(?<!\\b(?:Mr|Mrs|Ms|Dr)\\.)(?<!\\w\\.\\w\\.)(?<=[\\.!?][”\"]?) +', cleaned_text)\n",
        "twilight_sentences[5000:5020]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "mOOj3nYZxqax"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"demo\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "-luFwkL4xvQT"
      },
      "outputs": [],
      "source": [
        "# Define the prefixes\n",
        "prefixes = ['he', 'him', 'his', 'she', 'her', 'hers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xf9Q-4O-6XR",
        "outputId": "a625e67c-f876-4138-cfac-236453f5a347"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('urbanJJ', 120),\n",
              " ('legendNN', 182),\n",
              " ('storyNN', 167),\n",
              " ('contemporaryVB', 1),\n",
              " ('itPRP', 2733),\n",
              " ('typeNN', 4),\n",
              " ('popularJJ', 14),\n",
              " ('beliefNN', 3),\n",
              " (',,', 9554),\n",
              " ('sometimesRB', 39)]"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#horror parts of speech\n",
        "dfs = [pipeline.annotate(i.lower()) for i in horror_sentences]\n",
        "\n",
        "# Extract words and parts-of-speech\n",
        "tok_tag = [(df['token'],df['pos']) for df in dfs]\n",
        "\n",
        "# fuse pos to word\n",
        "zips = [list(zip(tt[0], tt[1])) for tt in tok_tag]\n",
        "horror_sentences_tagged = [\" \".join([\"\".join(word) for word in hl]) for hl in zips]\n",
        "\n",
        "#Count tagged words\n",
        "horror_tagged_spark = spark.sparkContext.parallelize(horror_sentences_tagged)\n",
        "\n",
        "horror_counts = (\n",
        "    horror_tagged_spark.flatMap(lambda line: line.split(\" \"))\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")\n",
        "\n",
        "horror_counts.collect()[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrAiibo9z_et",
        "outputId": "dc51ae71-afa8-46c0-cccc-ea286927b261"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('warningyouNN', 1),\n",
              " ('haveVBP', 1074),\n",
              " ('hatingVBG', 2),\n",
              " ('theDT', 7735),\n",
              " ('playerNN', 30),\n",
              " ('iNNP', 15725),\n",
              " ('wantVBP', 477),\n",
              " ('absolutelyRB', 31),\n",
              " ('horribleJJ', 43),\n",
              " ('languageNN', 9)]"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#romance parts of speech\n",
        "dfs = [pipeline.annotate(i.lower()) for i in romance_sentences]\n",
        "\n",
        "# Extract words and parts-of-speech\n",
        "tok_tag = [(df['token'],df['pos']) for df in dfs]\n",
        "\n",
        "# fuse pos to word\n",
        "zips = [list(zip(tt[0], tt[1])) for tt in tok_tag]\n",
        "romance_sentences_tagged = [\" \".join([\"\".join(word) for word in hl]) for hl in zips]\n",
        "\n",
        "#Count tagged words\n",
        "romance_tagged_spark = spark.sparkContext.parallelize(romance_sentences_tagged)\n",
        "\n",
        "romance_counts = (\n",
        "    romance_tagged_spark.flatMap(lambda line: line.split(\" \"))\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")\n",
        "\n",
        "romance_counts.collect()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiWz_Mhg0JBT",
        "outputId": "d1495837-28c0-43ea-e195-9a5d2d7c1e95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('hereRB', 640),\n",
              " ('knowVB', 620),\n",
              " ('aboutIN', 793),\n",
              " ('thisDT', 2117),\n",
              " ('particularJJ', 20),\n",
              " ('werewolfNN', 136),\n",
              " ('someDT', 512),\n",
              " ('appliesVBZ', 2),\n",
              " ('onlyRB', 519),\n",
              " ('myPRP$', 6591)]"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#warewolf parts of speech\n",
        "dfs = [pipeline.annotate(i.lower()) for i in warewolf_sentences]\n",
        "\n",
        "# Extract words and parts-of-speech\n",
        "tok_tag = [(df['token'],df['pos']) for df in dfs]\n",
        "\n",
        "# fuse pos to word\n",
        "zips = [list(zip(tt[0], tt[1])) for tt in tok_tag]\n",
        "warewolf_sentences_tagged = [\" \".join([\"\".join(word) for word in hl]) for hl in zips]\n",
        "\n",
        "#Count tagged words\n",
        "warewolf_tagged_spark = spark.sparkContext.parallelize(warewolf_sentences_tagged)\n",
        "\n",
        "warewolf_counts = (\n",
        "    warewolf_tagged_spark.flatMap(lambda line: line.split(\" \"))\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")\n",
        "\n",
        "warewolf_counts.collect()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_7lN2WK0U0q",
        "outputId": "a7b00d3c-d5ee-4ff8-cae5-8e39d294e1ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('12CD', 6),\n",
              " ('theDT', 10886),\n",
              " ('endNN', 71),\n",
              " (',,', 14040),\n",
              " ('shePRP', 3554),\n",
              " ('wasVBD', 3498),\n",
              " ('hereRB', 273),\n",
              " ('onlyRB', 361),\n",
              " ('everRB', 150),\n",
              " ('girlNN', 132)]"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#harrypotter parts of speech\n",
        "dfs = [pipeline.annotate(i.lower()) for i in harrypotter_sentences]\n",
        "\n",
        "# Extract words and parts-of-speech\n",
        "tok_tag = [(df['token'],df['pos']) for df in dfs]\n",
        "\n",
        "# fuse pos to word\n",
        "zips = [list(zip(tt[0], tt[1])) for tt in tok_tag]\n",
        "harrypotter_sentences_tagged = [\" \".join([\"\".join(word) for word in hl]) for hl in zips]\n",
        "\n",
        "#Count tagged words\n",
        "harrypotter_tagged_spark = spark.sparkContext.parallelize(harrypotter_sentences_tagged)\n",
        "\n",
        "harrypotter_counts = (\n",
        "    harrypotter_tagged_spark.flatMap(lambda line: line.split(\" \"))\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")\n",
        "\n",
        "harrypotter_counts.collect()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhNegW880gPZ",
        "outputId": "62288588-b270-4973-9bfb-6e031856c743"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('disclaimerNN', 1),\n",
              " ('iNNP', 3063),\n",
              " ('doVBP', 239),\n",
              " ('notRB', 611),\n",
              " ('ownVB', 6),\n",
              " ('theDT', 7124),\n",
              " ('twilightNN', 29),\n",
              " (\"don'tVBP\", 149),\n",
              " ('charactersNNS', 9),\n",
              " ('anythingNN', 170)]"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#twilight parts of speech\n",
        "dfs = [pipeline.annotate(i.lower()) for i in twilight_sentences]\n",
        "\n",
        "# Extract words and parts-of-speech\n",
        "tok_tag = [(df['token'],df['pos']) for df in dfs]\n",
        "\n",
        "# fuse pos to word\n",
        "zips = [list(zip(tt[0], tt[1])) for tt in tok_tag]\n",
        "twilight_sentences_tagged = [\" \".join([\"\".join(word) for word in hl]) for hl in zips]\n",
        "\n",
        "#Count tagged words\n",
        "twilight_tagged_spark = spark.sparkContext.parallelize(twilight_sentences_tagged)\n",
        "\n",
        "twilight_counts = (\n",
        "    twilight_tagged_spark.flatMap(lambda line: line.split(\" \"))\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")\n",
        "\n",
        "twilight_counts.collect()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQcS07tn_tcM",
        "outputId": "9f6ca3bd-0373-4a56-a905-82b5c9672eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('shePRP', 2391), ('hePRP', 3809), ('herPRP', 408), ('herPRP$', 2165), ('himPRP', 1100), ('hisPRP$', 2592), ('hersNNS', 2), ('hersPRP', 1)]\n",
            "Horror male subject pronoun proportion: 0.6544460738568191\n",
            "Horror female subject pronoun proportion: 0.5635192268975237\n"
          ]
        }
      ],
      "source": [
        "#Horror\n",
        "#Filter the RDD for keys that match the criteria\n",
        "filtered_rdd = horror_counts.filter(\n",
        "    lambda kv: any(\n",
        "        kv[0].lower().startswith(prefix) and kv[0][len(prefix):][0].isupper()\n",
        "        for prefix in prefixes\n",
        "    )\n",
        ")\n",
        "\n",
        "# Collect and print the results\n",
        "print(filtered_rdd.collect())\n",
        "\n",
        "#male subject pronouns and total male pronouns\n",
        "male_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP', 'hisPRP$'])\n",
        "male_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP'])\n",
        "summed_male_pronouns = male_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_male_pronouns_subjects = male_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#female subject pronouns and total female pronouns\n",
        "female_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP', 'herPRP$', 'hersNNS', 'hersPRP'])\n",
        "female_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP'])\n",
        "summed_female_pronouns = female_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_female_pronouns_subjects = female_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#pronoun proportions\n",
        "horror_male_pronouns_subject_proportion = summed_male_pronouns_subjects / summed_male_pronouns\n",
        "horror_female_pronouns_subject_proportion = summed_female_pronouns_subjects / summed_female_pronouns\n",
        "\n",
        "print(\"Horror male subject pronoun proportion: \" + str(horror_male_pronouns_subject_proportion))\n",
        "print(\"Horror female subject pronoun proportion: \" + str(horror_female_pronouns_subject_proportion))\n",
        "\n",
        "#[('shePRP', 2391), ('hePRP', 3809), ('herPRP', 408), ('herPRP$', 2165), ('himPRP', 1100), ('hisPRP$', 2592), ('hersNNS', 2), ('hersPRP', 1)]\n",
        "#Horror male subject pronoun proportion: 0.6544460738568191\n",
        "#Horror female subject pronoun proportion: 0.5635192268975237"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Izrp2h0rZ4",
        "outputId": "0af91586-6795-4c44-92f0-09bc1d0dfff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('hePRP', 4905), ('herPRP', 651), ('shePRP', 2928), ('himPRP', 2255), ('herPRP$', 2457), ('hisPRP$', 2763), ('hersPRP', 11), ('hersNNS', 12)]\n",
            "Romance male subject pronoun proportion: 0.7215559810541167\n",
            "Romance female subject pronoun proportion: 0.590691533256313\n"
          ]
        }
      ],
      "source": [
        "#Romance\n",
        "#Filter the RDD for keys that match the criteria\n",
        "filtered_rdd = romance_counts.filter(\n",
        "    lambda kv: any(\n",
        "        kv[0].lower().startswith(prefix) and kv[0][len(prefix):][0].isupper()\n",
        "        for prefix in prefixes\n",
        "    )\n",
        ")\n",
        "\n",
        "# Collect and print the results\n",
        "print(filtered_rdd.collect())\n",
        "\n",
        "#male subject pronouns and total male pronouns\n",
        "male_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP', 'hisPRP$'])\n",
        "male_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP'])\n",
        "summed_male_pronouns = male_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_male_pronouns_subjects = male_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#female subject pronouns and total female pronouns\n",
        "female_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP', 'herPRP$', 'hersNNS', 'hersPRP'])\n",
        "female_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP'])\n",
        "summed_female_pronouns = female_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_female_pronouns_subjects = female_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#pronoun proportions\n",
        "romance_male_pronouns_subject_proportion = summed_male_pronouns_subjects / summed_male_pronouns\n",
        "romance_female_pronouns_subject_proportion = summed_female_pronouns_subjects / summed_female_pronouns\n",
        "\n",
        "print(\"Romance male subject pronoun proportion: \" + str(romance_male_pronouns_subject_proportion))\n",
        "print(\"Romance female subject pronoun proportion: \" + str(romance_female_pronouns_subject_proportion))\n",
        "\n",
        "#[('hePRP', 4905), ('herPRP', 651), ('shePRP', 2928), ('himPRP', 2255), ('herPRP$', 2457), ('hisPRP$', 2763), ('hersPRP', 11), ('hersNNS', 12)]\n",
        "#Romance male subject pronoun proportion: 0.7215559810541167\n",
        "#Romance female subject pronoun proportion: 0.590691533256313"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D04JhGPZ1MYu",
        "outputId": "6ddf3036-1510-41f0-f736-156ac29b0097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('hePRP', 3662), ('shePRP', 3085), ('herPRP', 798), ('herPRP$', 4442), ('hisPRP$', 4217), ('himPRP', 1710), ('hersNNS', 41), ('hersPRP', 8)]\n",
            "Warewolf male subject pronoun proportion: 0.5602252581082491\n",
            "Warewolf female subject pronoun proportion: 0.46369715786959637\n"
          ]
        }
      ],
      "source": [
        "#Warewolf\n",
        "#Filter the RDD for keys that match the criteria\n",
        "filtered_rdd = warewolf_counts.filter(\n",
        "    lambda kv: any(\n",
        "        kv[0].lower().startswith(prefix) and kv[0][len(prefix):][0].isupper()\n",
        "        for prefix in prefixes\n",
        "    )\n",
        ")\n",
        "\n",
        "# Collect and print the results\n",
        "print(filtered_rdd.collect())\n",
        "\n",
        "#male subject pronouns and total male pronouns\n",
        "male_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP', 'hisPRP$'])\n",
        "male_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP'])\n",
        "summed_male_pronouns = male_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_male_pronouns_subjects = male_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#female subject pronouns and total female pronouns\n",
        "female_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP', 'herPRP$', 'hersNNS', 'hersPRP'])\n",
        "female_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP'])\n",
        "summed_female_pronouns = female_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_female_pronouns_subjects = female_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#pronoun proportions\n",
        "warewolf_male_pronouns_subject_proportion = summed_male_pronouns_subjects / summed_male_pronouns\n",
        "warewolf_female_pronouns_subject_proportion = summed_female_pronouns_subjects / summed_female_pronouns\n",
        "\n",
        "print(\"Warewolf male subject pronoun proportion: \" + str(warewolf_male_pronouns_subject_proportion))\n",
        "print(\"Warewolf female subject pronoun proportion: \" + str(warewolf_female_pronouns_subject_proportion))\n",
        "\n",
        "#[('hePRP', 3662), ('shePRP', 3085), ('herPRP', 798), ('herPRP$', 4442), ('hisPRP$', 4217), ('himPRP', 1710), ('hersNNS', 41), ('hersPRP', 8)]\n",
        "#Warewolf male subject pronoun proportion: 0.5602252581082491\n",
        "#Warewolf female subject pronoun proportion: 0.46369715786959637"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flZvM6xj1YpR",
        "outputId": "225bad36-d812-4045-c5d5-f9d0e1012b06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('shePRP', 3554), ('herPRP', 415), ('hePRP', 3592), ('herPRP$', 2633), ('hisPRP$', 2503), ('himPRP', 1347), ('hersNNS', 17), ('hersPRP', 6)]\n",
            "Harry Potter male subject pronoun proportion: 0.6636656812684762\n",
            "Harry Potter female subject pronoun proportion: 0.5990943396226415\n"
          ]
        }
      ],
      "source": [
        "#Harry potter\n",
        "#Filter the RDD for keys that match the criteria\n",
        "filtered_rdd = harrypotter_counts.filter(\n",
        "    lambda kv: any(\n",
        "        kv[0].lower().startswith(prefix) and kv[0][len(prefix):][0].isupper()\n",
        "        for prefix in prefixes\n",
        "    )\n",
        ")\n",
        "\n",
        "# Collect and print the results\n",
        "print(filtered_rdd.collect())\n",
        "\n",
        "#male subject pronouns and total male pronouns\n",
        "male_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP', 'hisPRP$'])\n",
        "male_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP'])\n",
        "summed_male_pronouns = male_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_male_pronouns_subjects = male_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#female subject pronouns and total female pronouns\n",
        "female_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP', 'herPRP$', 'hersNNS', 'hersPRP'])\n",
        "female_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP'])\n",
        "summed_female_pronouns = female_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_female_pronouns_subjects = female_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#pronoun proportions\n",
        "harrypotter_male_pronouns_subject_proportion = summed_male_pronouns_subjects / summed_male_pronouns\n",
        "harrypotter_female_pronouns_subject_proportion = summed_female_pronouns_subjects / summed_female_pronouns\n",
        "\n",
        "print(\"Harry Potter male subject pronoun proportion: \" + str(harrypotter_male_pronouns_subject_proportion))\n",
        "print(\"Harry Potter female subject pronoun proportion: \" + str(harrypotter_female_pronouns_subject_proportion))\n",
        "\n",
        "#[('shePRP', 3554), ('herPRP', 415), ('hePRP', 3592), ('herPRP$', 2633), ('hisPRP$', 2503), ('himPRP', 1347), ('hersNNS', 17), ('hersPRP', 6)]\n",
        "#Harry Potter male subject pronoun proportion: 0.6636656812684762\n",
        "#Harry Potter female subject pronoun proportion: 0.5990943396226415"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld1Si5nK1juS",
        "outputId": "8a674eec-d948-404f-9efa-2eb37e328bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('shePRP', 3554), ('hePRP', 2031), ('herPRP', 622), ('herPRP$', 4040), ('himPRP', 1016), ('hisPRP$', 1534), ('hersNNS', 15), ('hersPRP', 8)]\n",
            "Twilight male subject pronoun proportion: 0.6651386160227024\n",
            "Twilight female subject pronoun proportion: 0.5068576283529554\n"
          ]
        }
      ],
      "source": [
        "#Twilight\n",
        "#Filter the RDD for keys that match the criteria\n",
        "filtered_rdd = twilight_counts.filter(\n",
        "    lambda kv: any(\n",
        "        kv[0].lower().startswith(prefix) and kv[0][len(prefix):][0].isupper()\n",
        "        for prefix in prefixes\n",
        "    )\n",
        ")\n",
        "\n",
        "# Collect and print the results\n",
        "print(filtered_rdd.collect())\n",
        "\n",
        "#male subject pronouns and total male pronouns\n",
        "male_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP', 'hisPRP$'])\n",
        "male_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['hePRP', 'himPRP'])\n",
        "summed_male_pronouns = male_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_male_pronouns_subjects = male_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#female subject pronouns and total female pronouns\n",
        "female_pronouns = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP', 'herPRP$', 'hersNNS', 'hersPRP'])\n",
        "female_pronouns_subjects = filtered_rdd.filter(lambda kv: kv[0] in ['shePRP', 'herPRP'])\n",
        "summed_female_pronouns = female_pronouns.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "summed_female_pronouns_subjects = female_pronouns_subjects.map(lambda kv: kv[1]).reduce(lambda a, b: a + b)\n",
        "\n",
        "#pronoun proportions\n",
        "twilight_male_pronouns_subject_proportion = summed_male_pronouns_subjects / summed_male_pronouns\n",
        "twilight_female_pronouns_subject_proportion = summed_female_pronouns_subjects / summed_female_pronouns\n",
        "\n",
        "print(\"Twilight male subject pronoun proportion: \" + str(twilight_male_pronouns_subject_proportion))\n",
        "print(\"Twilight female subject pronoun proportion: \" + str(twilight_female_pronouns_subject_proportion))\n",
        "\n",
        "#[('shePRP', 3554), ('hePRP', 2031), ('herPRP', 622), ('herPRP$', 4040), ('himPRP', 1016), ('hisPRP$', 1534), ('hersNNS', 15), ('hersPRP', 8)]\n",
        "#Twilight male subject pronoun proportion: 0.6651386160227024\n",
        "#Twilight female subject pronoun proportion: 0.5068576283529554"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
